import os
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Set
from stock_data_fetcher_improved import ImprovedStockDataFetcher, STOCK_SYMBOLS

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AutoStockScheduler:
    def __init__(self, check_interval: int = 180):  # 3åˆ†é’Ÿ = 180ç§’
        self.check_interval = check_interval
        self.fetcher = ImprovedStockDataFetcher(api_delay=6.0, max_retries=2)
        self.data_dir = os.path.join(os.path.dirname(__file__), "auto_data")
        self.progress_file = os.path.join(self.data_dir, "progress.json")
        self._ensure_data_dir()
        self.progress = self._load_progress()
        
    def _ensure_data_dir(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            logger.info(f"åˆ›å»ºæ•°æ®ç›®å½•: {self.data_dir}")
    
    def _load_progress(self) -> Dict:
        """åŠ è½½è¿›åº¦æ–‡ä»¶"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½è¿›åº¦å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–è¿›åº¦
        return {
            "total_symbols": len(STOCK_SYMBOLS),
            "completed_symbols": [],
            "failed_symbols": [],
            "last_update": None,
            "start_time": datetime.now().isoformat(),
            "statistics": {
                "total_attempts": 0,
                "successful_fetches": 0,
                "failed_fetches": 0
            }
        }
    
    def _save_progress(self):
        """ä¿å­˜è¿›åº¦æ–‡ä»¶"""
        try:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.progress, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def get_pending_symbols(self) -> List[str]:
        """è·å–å¾…è·å–çš„è‚¡ç¥¨åˆ—è¡¨"""
        completed = set(self.progress["completed_symbols"])
        failed = set(self.progress["failed_symbols"])
        pending = [s for s in STOCK_SYMBOLS if s not in completed and s not in failed]
        return pending
    
    def fetch_next_batch(self, batch_size: int = 2) -> Dict:
        """è·å–ä¸‹ä¸€æ‰¹è‚¡ç¥¨æ•°æ®"""
        pending = self.get_pending_symbols()
        
        if not pending:
            logger.info("æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²è·å–å®Œæˆï¼")
            return {"status": "completed", "message": "æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²è·å–å®Œæˆ"}
        
        # è·å–ä¸‹ä¸€æ‰¹
        next_batch = pending[:batch_size]
        logger.info(f"å‡†å¤‡è·å– {len(next_batch)} åªè‚¡ç¥¨: {next_batch}")
        
        try:
            # ä½¿ç”¨fetcherè·å–æ•°æ®
            result = self.fetcher.fetch_batch_with_rate_limiting(
                symbols=next_batch,
                batch_size=batch_size,
                delay_between_batches=5.0  # æ‰¹æ¬¡é—´å»¶è¿Ÿå‡å°‘
            )
            
            # æ›´æ–°è¿›åº¦
            successful = result.get("successful_symbols", [])
            failed = result.get("failed_symbols", [])
            
            self.progress["completed_symbols"].extend(successful)
            self.progress["failed_symbols"].extend(failed)
            self.progress["statistics"]["total_attempts"] += len(next_batch)
            self.progress["statistics"]["successful_fetches"] += len(successful)
            self.progress["statistics"]["failed_fetches"] += len(failed)
            self.progress["last_update"] = datetime.now().isoformat()
            
            # ä¿å­˜å•ä¸ªè‚¡ç¥¨æ•°æ®
            for symbol, data in result.get("data", {}).items():
                if data.get("fetch_success", False):
                    self._save_single_stock(symbol, data)
            
            self._save_progress()
            
            logger.info(f"æ‰¹æ¬¡å®Œæˆ: æˆåŠŸ {len(successful)}, å¤±è´¥ {len(failed)}")
            
            return {
                "status": "success",
                "batch_size": len(next_batch),
                "successful": len(successful),
                "failed": len(failed),
                "remaining": len(pending) - len(next_batch)
            }
            
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡è·å–å¤±è´¥: {e}")
            return {"status": "error", "message": str(e)}
    
    def _save_single_stock(self, symbol: str, data: Dict):
        """ä¿å­˜å•ä¸ªè‚¡ç¥¨æ•°æ®"""
        try:
            filename = f"{symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(self.data_dir, filename)
            
            stock_data = {
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "data": data,
                "metadata": {
                    "fetch_success": True,
                    "file_created": datetime.now().isoformat()
                }
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(stock_data, f, ensure_ascii=False, indent=2)
                
            logger.info(f"âœ… å·²ä¿å­˜ {symbol} æ•°æ®åˆ°: {filename}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ {symbol} æ•°æ®å¤±è´¥: {e}")
    
    def get_status(self) -> Dict:
        """è·å–å½“å‰çŠ¶æ€"""
        pending = self.get_pending_symbols()
        completed = len(self.progress["completed_symbols"])
        failed = len(self.progress["failed_symbols"])
        
        return {
            "total_stocks": len(STOCK_SYMBOLS),
            "completed": completed,
            "failed": failed,
            "pending": len(pending),
            "completion_rate": round((completed + failed) / len(STOCK_SYMBOLS) * 100, 2),
            "last_update": self.progress["last_update"],
            "statistics": self.progress["statistics"],
            "next_batch": pending[:2] if pending else []
        }
    
    def run_continuous(self):
        """æŒç»­è¿è¡Œæ¨¡å¼"""
        logger.info("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–è‚¡ç¥¨æ•°æ®è·å–ç³»ç»Ÿ")
        logger.info(f"æ€»è‚¡ç¥¨æ•°: {len(STOCK_SYMBOLS)}")
        logger.info(f"æ£€æŸ¥é—´éš”: {self.check_interval}ç§’")
        
        try:
            while True:
                status = self.get_status()
                
                if status["pending"] == 0:
                    logger.info("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨æ•°æ®è·å–å®Œæˆï¼")
                    break
                
                logger.info(f"å½“å‰çŠ¶æ€: å®Œæˆ {status['completed']}, å¤±è´¥ {status['failed']}, å¾…è·å– {status['pending']}")
                
                # æ‰§è¡Œä¸‹ä¸€æ‰¹
                result = self.fetch_next_batch(batch_size=2)
                
                if result["status"] == "completed":
                    break
                
                # ç­‰å¾…ä¸‹ä¸€è½®
                logger.info(f"â³ ç­‰å¾… {self.check_interval} ç§’åè¿›è¡Œä¸‹ä¸€è½®...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨åœæ­¢...")
        except Exception as e:
            logger.error(f"è¿è¡Œé”™è¯¯: {e}")
    
    def run_once(self):
        """å•æ¬¡è¿è¡Œæ¨¡å¼"""
        logger.info("æ‰§è¡Œå•æ¬¡æ•°æ®è·å–...")
        return self.fetch_next_batch(batch_size=3)

# å¿«æ·å‡½æ•°
def start_auto_fetch():
    """å¯åŠ¨è‡ªåŠ¨è·å–"""
    scheduler = AutoStockScheduler(check_interval=180)  # 3åˆ†é’Ÿ
    scheduler.run_continuous()

def quick_status():
    """æŸ¥çœ‹å½“å‰çŠ¶æ€"""
    scheduler = AutoStockScheduler()
    return scheduler.get_status()

def run_single_batch():
    """è¿è¡Œå•æ‰¹æ¬¡"""
    scheduler = AutoStockScheduler()
    return scheduler.run_once()

if __name__ == "__main__":
    import sys
    
    print("ğŸ¤– è‡ªåŠ¨åŒ–è‚¡ç¥¨æ•°æ®è·å–è°ƒåº¦å™¨")
    print("=" * 50)
    
    scheduler = AutoStockScheduler()
    status = scheduler.get_status()
    
    print(f"å½“å‰çŠ¶æ€:")
    print(f"  æ€»è‚¡ç¥¨æ•°: {status['total_stocks']}")
    print(f"  å·²å®Œæˆ: {status['completed']}")
    print(f"  å¤±è´¥: {status['failed']}")
    print(f"  å¾…è·å–: {status['pending']}")
    print(f"  å®Œæˆç‡: {status['completion_rate']}%")
    
    print("\né€‰æ‹©æ“ä½œ:")
    print("1. å¯åŠ¨æŒç»­è·å– (æ¯3åˆ†é’Ÿä¸€è½®)")
    print("2. è¿è¡Œå•æ‰¹æ¬¡")
    print("3. æŸ¥çœ‹çŠ¶æ€")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3) [é»˜è®¤1]: ").strip() or "1"
    
    if choice == "1":
        print("\nğŸš€ å¯åŠ¨æŒç»­è·å–æ¨¡å¼...")
        print("æŒ‰ Ctrl+C åœæ­¢")
        start_auto_fetch()
    elif choice == "2":
        print("\nâš¡ è¿è¡Œå•æ‰¹æ¬¡...")
        result = run_single_batch()
        print(f"ç»“æœ: {result}")
    elif choice == "3":
        print(f"\nğŸ“Š çŠ¶æ€è¯¦æƒ…:")
        print(json.dumps(status, ensure_ascii=False, indent=2))
    else:
        print("æ— æ•ˆé€‰æ‹©")